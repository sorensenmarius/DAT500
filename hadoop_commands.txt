$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/hadoop-streaming.jar -input tweets/big.csv -output with_gender -mapper classify.py -file classify.py ../packages/mrjob.zip
hadoop fs -rm -r with_gender


python mappers/date_avg.py -r local --no-bootstrap-mrjob data/classified.csv > reduced_data/date_avg.csv

Create ssh tunnel to see Spark status locally:
ssh -L 8080:localhost:80 ubuntu@152.94.169.130 -i ~/.ssh/dat500